{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Deep_Learning_CH5.ipynb","provenance":[],"authorship_tag":"ABX9TyMoffml/pmZdkA6Up7Yr+Bn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"wlJKHWeJ2aBQ"},"outputs":[],"source":["# Introducing the convolutional network\n","\n","from keras import models\n","from keras import layers\n","\n","model = models.Sequential()\n","model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)))\n","model.add(layers.MaxPooling2D((2,2)))\n","model.add(layers.Conv2D(64, (3,3), activation='relu'))\n","model.add(layers.MaxPooling2D((2,2)))\n","model.add(layers.Conv2D(64, (3,3), activation='relu'))\n","\n","# Convert 3D tensor to 1D tensor\n","model.add(layers.Flatten())\n","\n","# Analyze the data using the dense layer\n","model.add(layers.Dense(64, activation='relu'))\n","model.add(layers.Dense(10, activation='softmax'))"]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zgt0QFvr2l0S","executionInfo":{"status":"ok","timestamp":1643175084232,"user_tz":-480,"elapsed":8,"user":{"displayName":"Smile Yoon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWVkwvBjx-rXtD608FD95Ze8M_7r_2Lohh5ZquO4=s64","userId":"08492174067066637630"}},"outputId":"e1b229ef-80fb-4670-e04d-d8fb351dcec4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 26, 26, 32)        320       \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n"," )                                                               \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 3, 3, 64)          36928     \n","                                                                 \n"," flatten (Flatten)           (None, 576)               0         \n","                                                                 \n"," dense (Dense)               (None, 64)                36928     \n","                                                                 \n"," dense_1 (Dense)             (None, 10)                650       \n","                                                                 \n","=================================================================\n","Total params: 93,322\n","Trainable params: 93,322\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# Let's analyze the mnist data\n","from keras.datasets import mnist\n","from keras.utils.all_utils import to_categorical\n","\n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n","train_images = train_images.reshape((60000,28,28,1))\n","train_images = train_images.astype('float32')/255\n","test_images = test_images.reshape((10000,28,28,1))\n","test_images = test_images.astype('float32')/255\n","\n","train_labels = to_categorical(train_labels)\n","test_labels = to_categorical(test_labels)\n","\n","model.compile(optimizer='rmsprop',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","model.fit(train_images, train_labels, epochs=5, batch_size=64)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u6LE8A6m3VTc","executionInfo":{"status":"ok","timestamp":1643175331888,"user_tz":-480,"elapsed":247662,"user":{"displayName":"Smile Yoon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWVkwvBjx-rXtD608FD95Ze8M_7r_2Lohh5ZquO4=s64","userId":"08492174067066637630"}},"outputId":"4c09ff94-d5cb-40dc-e679-2e101b895490"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","11501568/11490434 [==============================] - 0s 0us/step\n","Epoch 1/5\n","938/938 [==============================] - 55s 58ms/step - loss: 0.1706 - accuracy: 0.9463\n","Epoch 2/5\n","938/938 [==============================] - 49s 52ms/step - loss: 0.0465 - accuracy: 0.9859\n","Epoch 3/5\n","938/938 [==============================] - 48s 51ms/step - loss: 0.0326 - accuracy: 0.9905\n","Epoch 4/5\n","938/938 [==============================] - 48s 51ms/step - loss: 0.0240 - accuracy: 0.9929\n","Epoch 5/5\n","938/938 [==============================] - 47s 50ms/step - loss: 0.0184 - accuracy: 0.9943\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7ff686e0b950>"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["test_loss, test_acc = model.evaluate(test_images, test_labels)\n","test_acc"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IXtoo1dd5B-Q","executionInfo":{"status":"ok","timestamp":1643175334779,"user_tz":-480,"elapsed":2905,"user":{"displayName":"Smile Yoon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWVkwvBjx-rXtD608FD95Ze8M_7r_2Lohh5ZquO4=s64","userId":"08492174067066637630"}},"outputId":"77e7f28e-0e60-462b-f968-9f90f5dbe300"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 3s 9ms/step - loss: 0.0276 - accuracy: 0.9900\n"]},{"output_type":"execute_result","data":{"text/plain":["0.9900000095367432"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["# dogs and cats 데이터 불러오기\n","# C:\\Users\\rlsot\\OneDrive - unist.ac.kr\\바탕 화면\\칭화대 수업\\220117 여름방학 공부\n","import os\n","\n","base_dir = '/Users'\n","os.path.join(base_dir,'cats')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"0OP6iDWq54TQ","executionInfo":{"status":"ok","timestamp":1643175334780,"user_tz":-480,"elapsed":15,"user":{"displayName":"Smile Yoon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWVkwvBjx-rXtD608FD95Ze8M_7r_2Lohh5ZquO4=s64","userId":"08492174067066637630"}},"outputId":"05bc451b-3122-4823-a637-3093bdf26746"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/Users/cats'"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["from keras.applications import vgg16\n","\n","conv_base = vgg16.VGG16(weights = 'imagenet',\n","                  include_top = False,\n","                  input_shape = (150,150,3))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PtbbVxVMSiZM","executionInfo":{"status":"ok","timestamp":1643254825287,"user_tz":-480,"elapsed":3149,"user":{"displayName":"Smile Yoon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWVkwvBjx-rXtD608FD95Ze8M_7r_2Lohh5ZquO4=s64","userId":"08492174067066637630"}},"outputId":"faf9fe12-85dc-4eda-ef82-544c962ee215"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58892288/58889256 [==============================] - 0s 0us/step\n","58900480/58889256 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","source":["conv_base.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i70U6wfO09Hc","executionInfo":{"status":"ok","timestamp":1643175336125,"user_tz":-480,"elapsed":133,"user":{"displayName":"Smile Yoon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWVkwvBjx-rXtD608FD95Ze8M_7r_2Lohh5ZquO4=s64","userId":"08492174067066637630"}},"outputId":"e763fe46-81c9-473c-d3d1-1c209d0a48df"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"vgg16\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 150, 150, 3)]     0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 150, 150, 64)      1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 150, 150, 64)      36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 75, 75, 64)        0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 75, 75, 128)       73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 75, 75, 128)       147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 37, 37, 128)       0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 37, 37, 256)       295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 37, 37, 256)       590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 37, 37, 256)       590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 18, 18, 256)       0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 18, 18, 512)       1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 18, 18, 512)       2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 18, 18, 512)       2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 9, 9, 512)         0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 9, 9, 512)         2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 9, 9, 512)         2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 9, 9, 512)         2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n","                                                                 \n","=================================================================\n","Total params: 14,714,688\n","Trainable params: 14,714,688\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["from keras import models\n","from keras import layers\n","\n","model = models.Sequential()\n","model.add(conv_base)\n","model.add(layers.Flatten())\n","model.add(layers.Dense(256, activation='relu'))\n","model.add(layers.Dense(1, activation='sigmoid'))"],"metadata":{"id":"ccd7ILrn3N2j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5Ry0NRYN7bLx","executionInfo":{"status":"ok","timestamp":1643176121067,"user_tz":-480,"elapsed":3,"user":{"displayName":"Smile Yoon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWVkwvBjx-rXtD608FD95Ze8M_7r_2Lohh5ZquO4=s64","userId":"08492174067066637630"}},"outputId":"5ae982d7-0619-4018-d997-a66d60c79203"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," vgg16 (Functional)          (None, 4, 4, 512)         14714688  \n","                                                                 \n"," flatten_1 (Flatten)         (None, 8192)              0         \n","                                                                 \n"," dense_2 (Dense)             (None, 256)               2097408   \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 257       \n","                                                                 \n","=================================================================\n","Total params: 16,812,353\n","Trainable params: 16,812,353\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# Freezing\n","\n","conv_base.trainable = False"],"metadata":{"id":"UFhhCiq_7c5O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.preprocessing.image import ImageDataGenerator\n","from keras import optimizers\n","\n","# Augment the data\n","train_datagen = ImageDataGenerator(\n","    rescale = 1./255,\n","    rotation_range = 40,\n","    width_shift_range = 0.2,\n","    height_shift_range = 0.2,\n","    shear_range = 0.2,\n","    zoom_range = 0.2,\n","    horizontal_flip = True,\n","    fill_mode = 'nearest'\n",")\n","'''\n","test_datagen = ImageDataGenerator(rescale = 1./255)\n","# training 할 땐 왜곡을 주어 데이터량을 늘린다.\n","train_generator = train_datagen.flow_from_directory(\n","    train_dir,\n","    target_size = (150,150),\n","    batch_size = 20,\n","    class_mode = 'binary'\n",")\n","validation_generator = test_datagen.flow_from_directory(\n","    validation_dir,\n","    target_size = (150,150),\n","    batch_size = 20,\n","    class_mode = 'binary'\n",")\n","model.compile(loss = 'binary_crossentropy',\n","              optimizer = optimizers.RMSprop(lr=2e-5)),\n","              metrics=['acc'])\n","# 파일위치로부터 사진 불러오는 기능\n","\n","history = model.fit_generator(\n","    train_generator,\n","    steps_per_epochs = 100,\n","    epochs = 30,\n","    validation_data = validation_generator,\n","    validation_steps = 50\n",")\n","'''"],"metadata":{"id":"P2cwa0xW7lLD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Fine-tuning\n","\n","# Freezing all layers up to a specific one\n","conv_base.trainable = True\n","\n","set_trainable = False\n","for layer in conv_base.layers:\n","  if layer.name == 'block5_conv1':\n","    set_trainable = True\n","  if set_trainable:\n","    layer.trainable = True\n","  else:\n","    layer.trainable = False\n"],"metadata":{"id":"hEs5ZP1e8FtM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["conv_base.summary()\n","# block5_conv1,2,3 은 trainable 하게 바꼈고,\n","# 나머지는 untrainable 하게 설정됨."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"65FJp41__O88","executionInfo":{"status":"ok","timestamp":1643177163510,"user_tz":-480,"elapsed":4,"user":{"displayName":"Smile Yoon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWVkwvBjx-rXtD608FD95Ze8M_7r_2Lohh5ZquO4=s64","userId":"08492174067066637630"}},"outputId":"5f62fd07-dd32-4e5e-8940-8039f7ca0330"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"vgg16\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 150, 150, 3)]     0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 150, 150, 64)      1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 150, 150, 64)      36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 75, 75, 64)        0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 75, 75, 128)       73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 75, 75, 128)       147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 37, 37, 128)       0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 37, 37, 256)       295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 37, 37, 256)       590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 37, 37, 256)       590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 18, 18, 256)       0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 18, 18, 512)       1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 18, 18, 512)       2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 18, 18, 512)       2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 9, 9, 512)         0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 9, 9, 512)         2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 9, 9, 512)         2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 9, 9, 512)         2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n","                                                                 \n","=================================================================\n","Total params: 14,714,688\n","Trainable params: 7,079,424\n","Non-trainable params: 7,635,264\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["'''\n","# Fine-tuning the model\n","model.compile(loss = 'binary_crossentropy',\n","              optimizer = optimizers.RMSprop(lr=1e-5),\n","              metrics=['acc'])\n","\n","history = model.fit_generator(\n","    train_generator,\n","    steps_per_epochs = 100,\n","    epochs = 100,\n","    validation_data = validation_generator,\n","    validation_steps = 50\n",")\n","'''"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"cNyGVmmi_Q4M","executionInfo":{"status":"ok","timestamp":1643177295060,"user_tz":-480,"elapsed":469,"user":{"displayName":"Smile Yoon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWVkwvBjx-rXtD608FD95Ze8M_7r_2Lohh5ZquO4=s64","userId":"08492174067066637630"}},"outputId":"fd2db7f9-9225-42ba-975b-f803754d8e96"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\n# Fine-tuning the model\\nmodel.compile(loss = 'binary_crossentropy',\\n              optimizer = optimizers.RMSprop(lr=1e-5),\\n              metrics=['acc'])\\n\\nhistory = model.fit_generator(\\n    train_generator,\\n    steps_per_epochs = 100,\\n    epochs = 100,\\n    validation_data = validation_generator,\\n    validation_steps = 50\\n)\\n\""]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["'''\n","# Instantiating a model from an input tensor and a list of output tensors\n","\n","\n","\n","from keras import models\n","\n","layer_outputs = [layer.output for layer in model.layers[:8]]\n","activation_model = models.Model(inputs=model.input, outputs=layer_outputs)\n","activations = activation_model.predict(img_tensor)\n","\n","first_layer_activation = activations[0]\n","import matplotlib.pyplot as plt\n","# the results from the fourth channel\n","plt.matshow(first_layer_activation[0,:,:,4], cmap = 'viridis')\n","# the results from the seventh channel\n","plt.matshow(first_layer_activation[0,:,:,7], cmat = 'viridis')\n","'''"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":90},"id":"Tj0ybSBA_40E","executionInfo":{"status":"ok","timestamp":1643178720050,"user_tz":-480,"elapsed":608,"user":{"displayName":"Smile Yoon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWVkwvBjx-rXtD608FD95Ze8M_7r_2Lohh5ZquO4=s64","userId":"08492174067066637630"}},"outputId":"ba432690-2d2f-417c-bd43-c32f3e6da5ed"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\n# Instantiating a model from an input tensor and a list of output tensors\\n\\n\\n\\nfrom keras import models\\n\\nlayer_outputs = [layer.output for layer in model.layers[:8]]\\nactivation_model = models.Model(inputs=model.input, outputs=layer_outputs)\\nactivations = activation_model.predict(img_tensor)\\n\\nfirst_layer_activation = activations[0]\\nimport matplotlib.pyplot as plt\\n# the results from the fourth channel\\nplt.matshow(first_layer_activation[0,:,:,4], cmap = 'viridis')\\n# the results from the seventh channel\\nplt.matshow(first_layer_activation[0,:,:,7], cmat = 'viridis')\\n\""]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["'''\n","# Visualizing every channel in every intermediate activation\n","import matplotlib.pyplot as plt\n","import numpy as np\n","layer_names = []\n","for layer in model.layers[:8]:\n","  layer_names.append(layer.name)\n","images_per_row = 16\n","\n","for layer_name, layer_activation in zip(layer_names, activations):\n","  n_features = layer_activation.shape[-1]\n","  size = layer_activation.shape[1]\n","  n_cols = n_features//images_per_row\n","  display_grid = np.zeros((size*n_cols, images_per_row*size))\n","\n","  for col in range(n_cols):\n","    for row in range(images_per_row):\n","      channel_image = layer_activation[0, :, :, col*images_per_row + row]\n","      channel_image -= channel_image.mean()\n","      channel_image /= channel_image.std()\n","      channel_image *= 64\n","      channel_image += 128\n","      channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n","      display_grid[col*size : (col+1)*size, row*size : (row+1)*size] = channel_image\n","\n","  scale = 1./size\n","  plt.figure(figsize=(scale*display_grid.shape[1], scale*display_grid.shape[0]))\n","  plt.title(layer_name)\n","  plt.grid(False)\n","  plt.imshow(display_grid, aspect='auto', cmap='viridis')\n","'''\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":126},"id":"mLKJtkt1FXOd","executionInfo":{"status":"ok","timestamp":1643181003350,"user_tz":-480,"elapsed":12,"user":{"displayName":"Smile Yoon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWVkwvBjx-rXtD608FD95Ze8M_7r_2Lohh5ZquO4=s64","userId":"08492174067066637630"}},"outputId":"58554ae1-415e-4f29-f5c7-c7a9a37da893"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\n# Visualizing every channel in every intermediate activation\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\nlayer_names = []\\nfor layer in model.layers[:8]:\\n  layer_names.append(layer.name)\\nimages_per_row = 16\\n\\nfor layer_name, layer_activation in zip(layer_names, activations):\\n  n_features = layer_activation.shape[-1]\\n  size = layer_activation.shape[1]\\n  n_cols = n_features//images_per_row\\n  display_grid = np.zeros((size*n_cols, images_per_row*size))\\n\\n  for col in range(n_cols):\\n    for row in range(images_per_row):\\n      channel_image = layer_activation[0, :, :, col*images_per_row + row]\\n      channel_image -= channel_image.mean()\\n      channel_image /= channel_image.std()\\n      channel_image *= 64\\n      channel_image += 128\\n      channel_image = np.clip(channel_image, 0, 255).astype('uint8')\\n      display_grid[col*size : (col+1)*size, row*size : (row+1)*size] = channel_image\\n\\n  scale = 1./size\\n  plt.figure(figsize=(scale*display_grid.shape[1], scale*display_grid.shape[0]))\\n  plt.title(layer_name)\\n  plt.grid(False)\\n  plt.imshow(display_grid, aspect='auto', cmap='viridis')\\n\""]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["'''\n","# Defining the loss tensor for filter visualization\n","from keras.applications.vgg16 import VGG16\n","from keras import backend as K\n","\n","model = VGG16(weights='imagenet',\n","              include_top = False)\n","layer_name = 'block3_conv1'\n","filter_index = 0\n","\n","layer_output = model.get_layer(layer_name).output\n","loss = K.mean(layer_output[:,:,:,filter_index])\n","\n","grads = K.gradients(loss, model.input)[0]\n","grads /= (K.sqrt(K.mean(K.square(grads)))+1e-5) # L2 normalization\n","# iterate - loss 와 gradient 리턴함\n","iterate = K.function([model.input],[loss,grads])\n","import numpy as np\n","loss_value, grads_value = iterate([np.zeros((1,150,150,3))])\n","\n","''' "],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":71},"id":"QGY-Fh7AOEVZ","executionInfo":{"status":"ok","timestamp":1643181177030,"user_tz":-480,"elapsed":490,"user":{"displayName":"Smile Yoon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWVkwvBjx-rXtD608FD95Ze8M_7r_2Lohh5ZquO4=s64","userId":"08492174067066637630"}},"outputId":"6d87c558-4607-429c-bdc3-b82955b608d9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\n# Defining the loss tensor for filter visualization\\nfrom keras.applications.vgg16 import VGG16\\nfrom keras import backend as K\\n\\nmodel = VGG16(weights='imagenet',\\n              include_top = False)\\nlayer_name = 'block3_conv1'\\nfilter_index = 0\\n\\nlayer_output = model.get_layer(layer_name).output\\nloss = K.mean(layer_output[:,:,:,filter_index])\\n\\ngrads = K.gradients(loss, model.input)[0]\\ngrads /= (K.sqrt(K.mean(K.square(grads)))+1e-5)\\n\""]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":[""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":341},"id":"UTbt6fl7Of5k","executionInfo":{"status":"error","timestamp":1643181130332,"user_tz":-480,"elapsed":11,"user":{"displayName":"Smile Yoon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWVkwvBjx-rXtD608FD95Ze8M_7r_2Lohh5ZquO4=s64","userId":"08492174067066637630"}},"outputId":"243859d7-bbce-41d3-a0cd-6c46889496b3"},"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-d95e22c68b90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/backend.py\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(loss, variables)\u001b[0m\n\u001b[1;32m   4262\u001b[0m   \"\"\"\n\u001b[1;32m   4263\u001b[0m   return tf.compat.v1.gradients(\n\u001b[0;32m-> 4264\u001b[0;31m       loss, variables, colocate_gradients_with_ops=True)\n\u001b[0m\u001b[1;32m   4265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_ys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mgate_gradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maggregation_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         unconnected_gradients)\n\u001b[0m\u001b[1;32m    173\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[1;32m    480\u001b[0m   \u001b[0;34m\"\"\"Implementation of gradients().\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     raise RuntimeError(\"tf.gradients is not supported when eager execution \"\n\u001b[0m\u001b[1;32m    483\u001b[0m                        \"is enabled. Use tf.GradientTape instead.\")\n\u001b[1;32m    484\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msrc_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: tf.gradients is not supported when eager execution is enabled. Use tf.GradientTape instead."]}]},{"cell_type":"code","source":[""],"metadata":{"id":"awZ6-KQ6Oj2B"},"execution_count":null,"outputs":[]}]}